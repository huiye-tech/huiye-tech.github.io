[{"authors":null,"categories":null,"content":"The Phantom AI Research Group of Huiye Technology aims to power novel, exciting experiences in the virtual world and pioneer the future of AI.\nIf you are interested in the research topic of computer vision, computer graphics, neural language processing or audio processing for the application of animations, games and virtual characters, please send an email to research@huiye.tech\n","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"The Phantom AI Research Group of Huiye Technology aims to power novel, exciting experiences in the virtual world and pioneer the future of AI.\nIf you are interested in the research topic of computer vision, computer graphics, neural language processing or audio processing for the application of animations, games and virtual characters, please send an email to research@huiye.","tags":null,"title":"Huiye Technology","type":"authors"},{"authors":["Huiye Technology"],"categories":null,"content":"Overview In contrast to previous works that define the problem as generation of frames of motion state parameters, we formulate the task as a prediction of motion curves between key poses, which is inspired by the animation industry practice. The proposed framework, named DanceNet3D, first generates key poses on beats of the given music and then predicts the in-between motion curves. DanceNet3D adopts the encoder-decoder architecture and the adversarial schemes for training. The decoders in DanceNet3D are constructed on MoTrans, a transformer tailored for motion generation. In MoTrans we introduce the kinematic correlation by the Kinematic Chain Networks, and we also propose the Learned Local Attention module to take the temporal local correlation of human motion into consideration. Furthermore, we propose PhantomDance, the first large-scale dance dataset produced by professional animatiors, with accurate synchronization with music. Extensive experiments demonstrate that the proposed approach can generate fluent, elegant, performative and beat-synchronized 3D dances, which significantly surpasses previous works quantitatively and qualitatively.\nPaper Link Project Link Results Demo Videos \n\n\nComparison \nDataset We will realease 100 of the dataset as the PhantomDance-100 Dataset, which has 794776 frames(about 3.7 hours).\nTo obtain the PhantomDance-100 Dataset, please send an email to research@huiye.tech with the following information:\n(1) your name, title, affiliation (if you are a student, please ask your advisor to contact us)\n(2) your intended use of the data\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"cca1e882c56fbf83684e7e7d83deef89","permalink":"/post/dancenet3d/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/dancenet3d/","section":"post","summary":"In this work, we propose a novel deep learning framework that can generate a vivid dance from a whole piece of music.","tags":["Artificial Intelligence","Animation"],"title":"DanceNet3D: Music Based Dance Generation with Parametric Motion Transformer","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]