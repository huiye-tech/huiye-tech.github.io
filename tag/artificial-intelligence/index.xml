<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence | Phantom AI</title>
    <link>/tag/artificial-intelligence/</link>
      <atom:link href="/tag/artificial-intelligence/index.xml" rel="self" type="application/rss+xml" />
    <description>Artificial Intelligence</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 18 Mar 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_huef2d4e74d8587d735b1c4cc3154494f1_13577_512x512_fill_lanczos_center_2.png</url>
      <title>Artificial Intelligence</title>
      <link>/tag/artificial-intelligence/</link>
    </image>
    
    <item>
      <title>DanceNet3D: Music Based Dance Generation with Parametric Motion Transformer</title>
      <link>/project/dancenet3d/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/project/dancenet3d/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://huiye-tech.github.io/files/overview.jpg&#34; alt=&#34;overview&#34;&gt;
In contrast to previous works that define the problem as generation of frames of motion state parameters,
we formulate the task as a prediction of motion curves between key poses, which is inspired by the animation industry practice.
The proposed framework, named DanceNet3D, first generates key poses on beats of the given music and then predicts the in-between motion curves.
DanceNet3D adopts the encoder-decoder architecture and the adversarial schemes for training.
The decoders in DanceNet3D are constructed on MoTrans, a transformer tailored for motion generation.
In MoTrans we introduce the kinematic correlation by the Kinematic Chain Networks, and we also propose the Learned Local Attention module to take the temporal local correlation of human motion into consideration.
Furthermore, we propose PhantomDance, the first large-scale dance dataset produced by professional animatiors, with accurate synchronization with music.
Extensive experiments demonstrate that the proposed approach can generate fluent, elegant, performative and beat-synchronized 3D dances,
which significantly surpasses previous works quantitatively and qualitatively.&lt;/p&gt;
&lt;h5 id=&#34;paper-linkhttpsarxivorgabs210310206&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10206&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper Link&lt;/a&gt;&lt;/h5&gt;
&lt;h5 id=&#34;project-linkhttpsgithubcomhuiye-techdancenet3d&#34;&gt;&lt;a href=&#34;https://github.com/huiye-tech/DanceNet3D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Project Link&lt;/a&gt;&lt;/h5&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;h3 id=&#34;demo-videos&#34;&gt;Demo Videos&lt;/h3&gt;
&lt;p&gt;&lt;video src=&#34;https://huiye-tech.github.io/files/MangZhong.mp4&#34; width=&#34;1280px&#34; height=&#34;720px&#34; controls=&#34;controls&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;p&gt;&lt;video src=&#34;https://huiye-tech.github.io/files/Girls.mp4&#34; width=&#34;1280px&#34; height=&#34;720px&#34; controls=&#34;controls&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;p&gt;&lt;video src=&#34;https://huiye-tech.github.io/files/NiZuiZuiZuiZhongYao.mp4&#34; width=&#34;1280px&#34; height=&#34;720px&#34; controls=&#34;controls&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;h3 id=&#34;comparison&#34;&gt;Comparison&lt;/h3&gt;
&lt;p&gt;&lt;video src=&#34;https://huiye-tech.github.io/files/DanceNet3D_results.mp4&#34; width=&#34;2400px&#34; height=&#34;720px&#34; controls=&#34;controls&#34;&gt;&lt;/video&gt;&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;We will realease 100 of the dataset as the PhantomDance-100 Dataset, which has 794776 frames(about 3.7 hours).&lt;/p&gt;
&lt;p&gt;To obtain the PhantomDance-100 Dataset, please send an email to &lt;a href=&#34;mailto:research@huiye.tech&#34;&gt;research@huiye.tech&lt;/a&gt; with the following information:&lt;br&gt;
(1) your name, title, affiliation (if you are a student, please ask your advisor to contact us)&lt;br&gt;
(2) your intended use of the data&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
